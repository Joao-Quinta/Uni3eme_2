{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nb(X, y):\n",
    "    \"\"\"\n",
    "    Train the Naive Bayes classifier. For NB this is just\n",
    "    computing the necessary probabilities to perform classification\n",
    "    1. The probability P(ci) for every class -> prior (the prior comes from the distribution of labels)\n",
    "    2. The mean and std -> mean, std (The mean and variance are applied to each feature in the input data X)\n",
    "\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_train, D) containing the training data\n",
    "    consisting of num_train samples each of dimension D.\n",
    "    - y: A numpy array of shape (N,) containing the training labels, where\n",
    "        y[i] is the label for X[i].\n",
    "\n",
    "    Outputs:\n",
    "    - prior : list with length equal to the number of classes\n",
    "    - mean : A numpy array of shape (num_classes, num_features)\n",
    "    - std  : A numpy array of shape (num_classes, num_features)\n",
    "\n",
    "    **** train() should be run with X as training data\n",
    "    \"\"\"\n",
    "    # use list comprehension\n",
    "\n",
    "    # Separate training points by class\n",
    "    unique_y = np.unique (y) # returns a list of all differente values in y -> all possible classes\n",
    "    points_by_class = [[x for x, t in zip (X, y) if t == c] for c in unique_y]\n",
    "\n",
    "    #########################################################################\n",
    "    # TODO:                                                                 #\n",
    "    # compute class prior                                                   #\n",
    "    #########################################################################\n",
    "    \n",
    "    total = X.shape[0] #total number of data points\n",
    "    prior = [len(x)/total for x in points_by_class]\n",
    "\n",
    "    #########################################################################\n",
    "    # TODO:                                                                 #\n",
    "    # Estimate mean and std for each class / feature                        #\n",
    "    #########################################################################\n",
    "    \n",
    "    #colMeanC0 = x_iris[y_iris==0].mean(axis = 0)\n",
    "    mean = [X[y==c].mean(axis = 0) for c in unique_y]\n",
    "    std = [X[y==c].var(axis = 0) for c in unique_y]\n",
    "    \n",
    "    return prior, np.array(mean), np.array(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution(x, mean, std):\n",
    "    \"\"\"\n",
    "    Compute normal distribution\n",
    "    output size: (num_input_data, num_features)\n",
    "\n",
    "    \"\"\"\n",
    "    #########################################################################\n",
    "    # TODO : Compute normal distribution                                    #\n",
    "    #########################################################################\n",
    "\n",
    "    #normal =\n",
    "\n",
    "    return normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, prior, mean, std):\n",
    "    \"\"\"\n",
    "    Using the dustributions from before, predict labels for test data (or train data) using this classifier.\n",
    "    We predict the class of the data maximizing the likelihood or you can\n",
    "     maximize the log likelihood to make it numericaly more stable.\n",
    "     (This is possible since f(x)=log(x) is a monotone function)\n",
    "\n",
    "    You have to compute:\n",
    "    - Compute the conditional probabilities  P(x|c) (or log P(x|c) )\n",
    "    - The posterior (if you compute the log likelihood the product  becomes sum)\n",
    "    - Make the prediction\n",
    "\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_test, D) containing test data consisting\n",
    "        of num_test samples each of dimension D.\n",
    "    - prior, mean, std: output of train() function\n",
    "\n",
    "    Returns:\n",
    "    - y_pred : A numpy array of shape (num_test,) containing predicted labels for the\n",
    "    test data, where y[i] is the predicted label for the test point X[i].\n",
    "\n",
    "    *** predict() should be run with X as test data, based on mean and variance and prior from the training data\n",
    "        (to compute the training accuracy run with X as train data)\n",
    "\n",
    "    \"\"\"\n",
    "    # use list comprehension\n",
    "\n",
    "    #################################################################################\n",
    "    #        # Compute the conditional probabilities  P(x|c)                        #\n",
    "    #             # There are three loops in the code.                              #\n",
    "    #             # 1. through each sample.                                         #\n",
    "    #             # 2. through each class.                                          #\n",
    "    #             # 3. through each attribute and apply the Normal/ logNormal distribution. #\n",
    "    #        # Compute the posterior                                                #\n",
    "    #                                                                               #\n",
    "    #################################################################################\n",
    "\n",
    "\n",
    "    #########################################################################\n",
    "    #                           TODO\n",
    "    #             compute the posterior and predict                         #\n",
    "    # - hint for prediction: class having the biggest probability[argmax()] #\n",
    "    #########################################################################\n",
    "    y_predd = []\n",
    "    #pre = la proba prior pour chaque classe\n",
    "    for x in X:\n",
    "        eachClass = []\n",
    "        for c in range(0,len(prior)):\n",
    "            eachClass.append(prior[c] * np.prod([np.exp(-1*np.square((x[attrN]-mean[c][attrN])/(2*std[c][attrN]))) for attrN in range(0,len(x))]))\n",
    "        y_predd.append(np.argmax(eachClass))\n",
    "        \n",
    "    return y_predd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_IRIS(test=True):\n",
    "    iris = datasets.load_iris()\n",
    "    X, y = shuffle(iris.data, iris.target, random_state= 400)\n",
    "    if test:\n",
    "        X_train = X[:100, :]\n",
    "        y_train = y[:100]\n",
    "        X_test = X[100:, :]\n",
    "        y_test = y[100:]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "        X = iris.data\n",
    "        y = iris.target\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (150, 4)\n",
      "Target shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "# load the iris data set\n",
    "x_iris, y_iris = load_IRIS(test=False)\n",
    "X_train, y_train, X_test, y_test = load_IRIS(test=True)\n",
    "# chech the shape of the data anf target\n",
    "print('Data shape:', x_iris.shape)\n",
    "print('Target shape:', y_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "(3, 4)\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  0  __ predict :  1  __ rep :  False\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  0  __ predict :  0  __ rep :  True\n",
      "vrai :  2  __ predict :  2  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n",
      "vrai :  1  __ predict :  1  __ rep :  True\n"
     ]
    }
   ],
   "source": [
    "prior, mean, var = train_nb(x_iris, y_iris)\n",
    "print(prior)\n",
    "print(mean.shape)\n",
    "y_predict = predict(X_test, prior, mean, var)\n",
    "\n",
    "for i in range(0,len(y_predict)):\n",
    "    rep = y_test[i] == y_predict[i]\n",
    "    print(\"vrai : \",y_test[i], \" __ predict : \", y_predict[i], \" __ rep : \", rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
