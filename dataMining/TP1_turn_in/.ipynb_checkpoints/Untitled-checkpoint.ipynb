{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nb(X, y):\n",
    "    \"\"\"\n",
    "    Train the Naive Bayes classifier. For NB this is just\n",
    "    computing the necessary probabilities to perform classification\n",
    "    1. The probability P(ci) for every class -> prior (the prior comes from the distribution of labels)\n",
    "    2. The mean and std -> mean, std (The mean and variance are applied to each feature in the input data X)\n",
    "\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_train, D) containing the training data\n",
    "    consisting of num_train samples each of dimension D.\n",
    "    - y: A numpy array of shape (N,) containing the training labels, where\n",
    "        y[i] is the label for X[i].\n",
    "\n",
    "    Outputs:\n",
    "    - prior : list with length equal to the number of classes\n",
    "    - mean : A numpy array of shape (num_classes, num_features)\n",
    "    - std  : A numpy array of shape (num_classes, num_features)\n",
    "\n",
    "    **** train() should be run with X as training data\n",
    "    \"\"\"\n",
    "    # use list comprehension\n",
    "\n",
    "    # Separate training points by class\n",
    "    unique_y = np.unique (y) # returns a list of all differente values in y -> all possible classes\n",
    "    points_by_class = [[x for x, t in zip (X, y) if t == c] for c in unique_y]\n",
    "\n",
    "    #########################################################################\n",
    "    # TODO:                                                                 #\n",
    "    # compute class prior                                                   #\n",
    "    #########################################################################\n",
    "    \n",
    "    total = X.shape[0] #total number of data points\n",
    "    prior = [len(x)/total for x in points_by_class]\n",
    "\n",
    "    #########################################################################\n",
    "    # TODO:                                                                 #\n",
    "    # Estimate mean and std for each class / feature                        #\n",
    "    #########################################################################\n",
    "    \n",
    "    #colMeanC0 = x_iris[y_iris==0].mean(axis = 0)\n",
    "    mean = [X[y==c].mean(axis = 0) for c in unique_y]\n",
    "    std = [X[y==c].var(axis = 0) for c in unique_y]\n",
    "    \n",
    "    return prior, np.array(mean), np.array(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution(x, mean, std):\n",
    "    \"\"\"\n",
    "    Compute normal distribution\n",
    "    output size: (num_input_data, num_features)\n",
    "\n",
    "    \"\"\"\n",
    "    #########################################################################\n",
    "    # TODO : Compute normal distribution                                    #\n",
    "    #########################################################################\n",
    "\n",
    "    #normal =\n",
    "\n",
    "    return normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, prior, mean, std):\n",
    "    \"\"\"\n",
    "    Using the dustributions from before, predict labels for test data (or train data) using this classifier.\n",
    "    We predict the class of the data maximizing the likelihood or you can\n",
    "     maximize the log likelihood to make it numericaly more stable.\n",
    "     (This is possible since f(x)=log(x) is a monotone function)\n",
    "\n",
    "    You have to compute:\n",
    "    - Compute the conditional probabilities  P(x|c) (or log P(x|c) )\n",
    "    - The posterior (if you compute the log likelihood the product  becomes sum)\n",
    "    - Make the prediction\n",
    "\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_test, D) containing test data consisting\n",
    "        of num_test samples each of dimension D.\n",
    "    - prior, mean, std: output of train() function\n",
    "\n",
    "    Returns:\n",
    "    - y_pred : A numpy array of shape (num_test,) containing predicted labels for the\n",
    "    test data, where y[i] is the predicted label for the test point X[i].\n",
    "\n",
    "    *** predict() should be run with X as test data, based on mean and variance and prior from the training data\n",
    "        (to compute the training accuracy run with X as train data)\n",
    "\n",
    "    \"\"\"\n",
    "    # use list comprehension\n",
    "\n",
    "    #################################################################################\n",
    "    #        # Compute the conditional probabilities  P(x|c)                        #\n",
    "    #             # There are three loops in the code.                              #\n",
    "    #             # 1. through each sample.                                         #\n",
    "    #             # 2. through each class.                                          #\n",
    "    #             # 3. through each attribute and apply the Normal/ logNormal distribution. #\n",
    "    #        # Compute the posterior                                                #\n",
    "    #                                                                               #\n",
    "    #################################################################################\n",
    "\n",
    "\n",
    "    #########################################################################\n",
    "    #                           TODO\n",
    "    #             compute the posterior and predict                         #\n",
    "    # - hint for prediction: class having the biggest probability[argmax()] #\n",
    "    #########################################################################\n",
    "\n",
    "    # posterior =\n",
    "\n",
    "    # y_pred =\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_IRIS(test=True):\n",
    "    iris = datasets.load_iris()\n",
    "    X, y = shuffle(iris.data, iris.target, random_state= 400)\n",
    "    if test:\n",
    "        X_train = X[:100, :]\n",
    "        y_train = y[:100]\n",
    "        X_test = X[100:, :]\n",
    "        y_test = y[100:]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "        X = iris.data\n",
    "        y = iris.target\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (150, 4)\n",
      "Target shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "# load the iris data set\n",
    "x_iris, y_iris = load_IRIS(test=False)\n",
    "X_train, y_train, X_test, y_test = load_IRIS(test=True)\n",
    "# chech the shape of the data anf target\n",
    "print('Data shape:', x_iris.shape)\n",
    "print('Target shape:', y_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "prior, mean, var = train_nb(x_iris, y_iris)\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3 3.3 4.7 1.6]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.  2.2 5.  1.5]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.7 3.8 1.7 0.3]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'normal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-277e6aac2a38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-114-4ea7b7615577>\u001b[0m in \u001b[0;36mnormal_distribution\u001b[1;34m(x, mean, std)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#normal =\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnormal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'normal' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(normal_distribution(X_train, 0, 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
