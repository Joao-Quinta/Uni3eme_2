{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120725c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_smiles_encodings, load_data, smile_to_hot\n",
    "from model_regression import LinearRegression_RidgeRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "'''https://medium.com/coinmonks/support-vector-regression-or-svr-8eb3acf6d0ff'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395a0aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X - train :  (92428,)\n",
      "y - train :  (92428, 4)\n",
      "X_hot :  (92428, 14)\n",
      "X_hot_test :  (39612, 14)\n",
      "y_train [[  0.6361    0.       16.043     0.     ]\n",
      " [  0.162     0.       17.031     0.     ]\n",
      " [ -0.8247    0.       18.015     0.     ]\n",
      " ...\n",
      " [ -0.5388    0.      130.143     1.     ]\n",
      " [ -1.7719    0.      131.131     1.     ]\n",
      " [ -0.89423   0.      131.131     1.     ]]\n",
      "y_test [[ -1.3449   0.     132.115    1.    ]\n",
      " [  1.9317   0.     124.183    1.    ]\n",
      " [  1.0462   0.     125.171    1.    ]\n",
      " ...\n",
      " [ -0.8808   0.     120.155    8.    ]\n",
      " [  0.3187   0.     119.167    8.    ]\n",
      " [ -0.55     0.     121.139    8.    ]]\n"
     ]
    }
   ],
   "source": [
    "file_smiles = './dataset/QM9.txt'\n",
    "file_properties = './dataset/properties_QM9.npz'\n",
    "smiles, alphabet, largest_molecule_len = get_smiles_encodings(file_smiles)\n",
    "properties = np.load(file_properties)['properties'].astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(smiles, properties)\n",
    "print(\"X - train : \", X_train.shape)\n",
    "print(\"y - train : \", y_train.shape)\n",
    "X_hot = np.array([smile_to_hot(x, largest_molecule_len, alphabet)[1].sum(axis=0) for x in X_train])\n",
    "#print(\"X_hot\", X_hot)\n",
    "X_hot_test = np.array([smile_to_hot(x, largest_molecule_len, alphabet)[1].sum(axis=0) for x in X_test])\n",
    "#print(\"X_hot_test\", X_hot_test)\n",
    "print(\"X_hot : \", X_hot.shape)\n",
    "print(\"X_hot_test : \", X_hot_test.shape)\n",
    "print(\"y_train\", y_train)\n",
    "print(\"y_test\",y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1da5c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done : y_pred_0\n",
      "y_pred_0 [-1.04298227  1.8759916   1.24370983 ... -0.63408629  0.36238152\n",
      " -0.53342194]\n",
      "y_pred_0 len 39612\n"
     ]
    }
   ],
   "source": [
    "#n_samples, n_features = 10, 5\n",
    "#rng = np.random.RandomState(0)\n",
    "#y = rng.randn(n_samples)\n",
    "#X = rng.randn(n_samples, n_features)\n",
    "regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X_hot, y_train[:,0])\n",
    "y_pred_0 = regr.predict(X_hot_test)\n",
    "print(\"done : y_pred_0\")\n",
    "print(\"y_pred_0\",y_pred_0)\n",
    "print(\"y_pred_0 len\", len(y_pred_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a5b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done : y_pred_1\n",
      "done : y_pred_2\n",
      "done : y_pred_3\n"
     ]
    }
   ],
   "source": [
    "regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X_hot, y_train[:,1])\n",
    "y_pred_1 = regr.predict(X_hot_test)\n",
    "\n",
    "print(\"done : y_pred_1\")\n",
    "\n",
    "regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X_hot, y_train[:,2])\n",
    "y_pred_2 = regr.predict(X_hot_test)\n",
    "\n",
    "print(\"done : y_pred_2\")\n",
    "\n",
    "regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X_hot, y_train[:,3])\n",
    "y_pred_3 = regr.predict(X_hot_test)\n",
    "print(\"done : y_pred_3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "way too much time \n",
    "'''C_rate = [0.01,0.1,1.0,10.0,100.0]\n",
    "kernel_function = [\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"precomputed\"]\n",
    "epsilon_rate = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "best_0 = [100,0,0,0]\n",
    "best_1 = [100,0,0,0]\n",
    "best_2 = [100,0,0,0]\n",
    "best_3 = [100,0,0,0]\n",
    "\n",
    "#we iterate over loss function and learning rates\n",
    "for kernel in kernel_function:\n",
    "    for C in C_rate:\n",
    "        for eps in epsilon_rate:\n",
    "            # 0 \n",
    "            regr = make_pipeline(StandardScaler(), SVR(C=C, epsilon=eps, kernel=kernel))\n",
    "            regr.fit(X_hot, y_train[:,0])\n",
    "            y_pred_0 = regr.predict(X_hot_test)\n",
    "\n",
    "            # 1\n",
    "            regr = make_pipeline(StandardScaler(), SVR(C=C, epsilon=eps, kernel=kernel))\n",
    "            regr.fit(X_hot, y_train[:,1])\n",
    "            y_pred_1 = regr.predict(X_hot_test)\n",
    "            y_pred_1 = np.round(y_pred_1)\n",
    "\n",
    "            # 2 \n",
    "            regr = make_pipeline(StandardScaler(), SVR(C=C, epsilon=eps, kernel=kernel))\n",
    "            regr.fit(X_hot, y_train[:,2])\n",
    "            y_pred_2 = regr.predict(X_hot_test)\n",
    "\n",
    "            # 3 \n",
    "            regr = make_pipeline(StandardScaler(), SVR(C=C, epsilon=eps, kernel=kernel))\n",
    "            regr.fit(X_hot, y_train[:,3])\n",
    "            y_pred_3 = regr.predict(X_hot_test)\n",
    "            y_pred_3 = np.round(y_pred_3)\n",
    "\n",
    "            # calcul res\n",
    "            sum_0 = 0\n",
    "            sum_1 = 0\n",
    "            sum_2 = 0\n",
    "            sum_3 = 0\n",
    "            for i in range(y_test_0.shape[0]):\n",
    "\n",
    "                # 0\n",
    "                sum_0 = sum_0 + np.abs(np.abs(y_pred_0[i]) - np.abs(y_test_0[i]))\n",
    "\n",
    "                # 1\n",
    "                if(y_pred_1[i] == y_test_1[i]):\n",
    "                    sum_1 = sum_1 + 1\n",
    "\n",
    "                # 2\n",
    "                sum_2 = sum_2 + np.abs(np.abs(y_pred_2[i]) - np.abs(y_test_2[i]))\n",
    "\n",
    "                # 3\n",
    "                if(y_pred_3[i] == y_test_3[i]):\n",
    "                    sum_3 = sum_3 + 1\n",
    "\n",
    "            sum_0 = sum_0 / y_test_0.shape[0]\n",
    "            sum_1_r = 100 - (sum_1 / y_test_1.shape[0] * 100)\n",
    "            sum_2 = sum_2 / y_test_2.shape[0]\n",
    "            sum_3_r = 100 - (sum_3 / y_test_3.shape[0] * 100)\n",
    "\n",
    "\n",
    "            # change res if needed\n",
    "            if sum_0 < best_0[0]:\n",
    "                best_0 = [sum_0, kernel, C, eps]\n",
    "\n",
    "            if sum_1_r < best_1[0]:\n",
    "                best_1 = [sum_1_r, kernel, C, eps]\n",
    "\n",
    "            if sum_2 < best_2[0]:\n",
    "                best_2 = [sum_2, kernel, C, eps]\n",
    "\n",
    "            if sum_3_r < best_3[0]:\n",
    "                best_3 = [sum_3_r, kernel, C, eps]\n",
    "\n",
    "            print(kernel, \" \", C, \" \", eps,\"   - done\")\n",
    "        \n",
    "print()                \n",
    "print(best_0)\n",
    "print(best_1)\n",
    "print(best_2)\n",
    "print(best_3)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328e975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb8405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d36882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_regression_0 = SGDRegressor()\n",
    "#model_regression_0.fit(X_hot, y_train[:,0])\n",
    "#y_pred_0 = model_regression_0.predict(X_hot_test)\n",
    "#print(\"y_pred_0\",y_pred_0)\n",
    "#print(\"y_pred_0 len\", len(y_pred_0))\n",
    "#model_regression_1 = SGDRegressor()\n",
    "#model_regression_1.fit(X_hot, y_train[:,1])\n",
    "#y_pred_1 = model_regression_1.predict(X_hot_test)\n",
    "#print(\"y_pred_1\",y_pred_1)\n",
    "#print(\"y_pred_1 len\", len(y_pred_1))\n",
    "#model_regression_2 = SGDRegressor()\n",
    "#model_regression_2.fit(X_hot, y_train[:,2])\n",
    "#y_pred_2 = model_regression_2.predict(X_hot_test)\n",
    "\n",
    "#model_regression_3 = SGDRegressor()\n",
    "#model_regression_3.fit(X_hot, y_train[:,3])\n",
    "#y_pred_3 = model_regression_3.predict(X_hot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f79bc942",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_0 = y_test[:,0]\n",
    "y_test_1 = y_test[:,1]\n",
    "y_test_2 = y_test[:,2]\n",
    "y_test_3 = y_test[:,3]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d850cd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in y_test[:,0] :  6400\n",
      "Min of y_test[:,0] :  -2.8142\n",
      "Max of y_test[:,0] :  3.7569\n",
      "\n",
      "Number of unique values in y_pred :  1337\n",
      "Min of y_pred :  -2.334036396869283\n",
      "Max of y_pred :  3.311236179902073\n",
      "\n",
      "Error is on avearage :  0.26732008420568637\n",
      "Let's say the target value is : 1.0, then the model would guess a value in the following interval :\n",
      " -> [ 0.7326799157943136 , 1.2673200842056864 ]\n",
      "Number of unique values in y_pred_rounded :  6\n",
      "Min of y_pred_rounded :  -2.0\n",
      "Max of y_pred_rounded :  3.0\n",
      "\n",
      "Error is on avearage :  0.3783025520998184\n",
      "There were  0  correct predictions, out of  39612 , which is  100.0 % error rate\n"
     ]
    }
   ],
   "source": [
    "sum_0 = 0\n",
    "for i in range(y_test_0.shape[0]):\n",
    "    sum_0 = sum_0 + np.abs(np.abs(y_pred_0[i]) - np.abs(y_test_0[i]))\n",
    "sum_0 = sum_0 / y_test_0.shape[0]\n",
    "\n",
    "\n",
    "print(\"Number of unique values in y_test[:,0] : \", np.unique(y_test_0).shape[0])\n",
    "print(\"Min of y_test[:,0] : \", np.min(y_test_0))\n",
    "print(\"Max of y_test[:,0] : \", np.max(y_test_0))\n",
    "print()\n",
    "print(\"Number of unique values in y_pred : \", np.unique(y_pred_0).shape[0])\n",
    "print(\"Min of y_pred : \", np.min(y_pred_0))\n",
    "print(\"Max of y_pred : \", np.max(y_pred_0))\n",
    "print()\n",
    "print(\"Error is on avearage : \", sum_0)\n",
    "print(\"Let's say the target value is : 1.0, then the model would guess a value in the following interval :\")\n",
    "print(\" -> [\", 1.0 - sum_0,\",\",1.0 + sum_0,\"]\")\n",
    "\n",
    "\n",
    "y_pred_0_r = np.around(y_pred_0)\n",
    "\n",
    "sum_0_r = 0\n",
    "sum_0_5_r = 0\n",
    "for i in range(y_pred_0_r.shape[0]):\n",
    "    sum_0_r = sum_0_r + np.abs(np.abs(y_pred_0_r[i]) - np.abs(y_test_0[i]))\n",
    "    if(y_pred_0_r[i] == y_test_0[i]):\n",
    "        sum_0_5_r = sum_0_5_r + 1\n",
    "sum_0_r = sum_0_r / y_test_0.shape[0]\n",
    "sum_0_5_r_ = sum_0_5_r / y_test_0.shape[0] * 100\n",
    "\n",
    "print(\"Number of unique values in y_pred_rounded : \", np.unique(y_pred_0_r).shape[0])\n",
    "print(\"Min of y_pred_rounded : \", np.min(y_pred_0_r))\n",
    "print(\"Max of y_pred_rounded : \", np.max(y_pred_0_r))\n",
    "print()\n",
    "print(\"Error is on avearage : \", sum_0_r)\n",
    "print(\"There were \", sum_0_5_r, \" correct predictions, out of \", y_test_1.shape[0], \", which is \", 100 - sum_0_5_r_,\"% error rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec6fb7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in y_test[:,1] :  7\n",
      "Min of y_test[:,1] :  0.0\n",
      "Max of y_test[:,1] :  6.0\n",
      "\n",
      "Number of unique values in y_pred :  1337\n",
      "Min of y_pred :  -0.21982706055818502\n",
      "Max of y_pred :  5.65719387254661\n",
      "\n",
      "Error is on avearage :  0.6956854528961844\n",
      "There were  0  correct predictions, out of  39612 , which is  100.0 % error rate\n",
      "\n",
      "Since the number of unique values is small, let's round the y_pred, to see if we get a better approximation : \n",
      "\n",
      "Number of unique values in y_pred_rounded :  7\n",
      "Min of y_pred_rounded :  0.0\n",
      "Max of y_pred_rounded :  6.0\n",
      "\n",
      "Error is on avearage :  0.6840603857416945\n",
      "There were  16846  correct predictions, out of  39612 , which is  57.472483085933554 % error rate\n"
     ]
    }
   ],
   "source": [
    "sum_1 = 0\n",
    "sum_1_5 = 0\n",
    "for i in range(y_test_1.shape[0]):\n",
    "    sum_1 = sum_1 + np.abs(np.abs(y_pred_1[i]) - np.abs(y_test_1[i]))\n",
    "    if(y_pred_1[i] == y_test_1[i]):\n",
    "        sum_1_5 = sum_1_5 + 1\n",
    "sum_1 = sum_1 / y_test_1.shape[0]\n",
    "sum_1_5_r = sum_1_5 / y_test_1.shape[0] * 100\n",
    "\n",
    "print(\"Number of unique values in y_test[:,1] : \", np.unique(y_test_1).shape[0])\n",
    "print(\"Min of y_test[:,1] : \", np.min(y_test_1))\n",
    "print(\"Max of y_test[:,1] : \", np.max(y_test_1))\n",
    "print()\n",
    "print(\"Number of unique values in y_pred : \", np.unique(y_pred_1).shape[0])\n",
    "print(\"Min of y_pred : \", np.min(y_pred_1))\n",
    "print(\"Max of y_pred : \", np.max(y_pred_1))\n",
    "print()\n",
    "print(\"Error is on avearage : \", sum_1)\n",
    "print(\"There were \", sum_1_5, \" correct predictions, out of \", y_test_1.shape[0], \", which is \", 100 - sum_1_5_r,\"% error rate\")\n",
    "print()\n",
    "print(\"Since the number of unique values is small, let's round the y_pred, to see if we get a better approximation : \")\n",
    "print()\n",
    "\n",
    "y_pred_1_r = np.around(y_pred_1)\n",
    "\n",
    "sum_1_r = 0\n",
    "sum_1_5_r = 0\n",
    "for i in range(y_pred_1_r.shape[0]):\n",
    "    sum_1_r = sum_1_r + np.abs(np.abs(y_pred_1_r[i]) - np.abs(y_test_1[i]))\n",
    "    if(y_pred_1_r[i] == y_test_1[i]):\n",
    "        sum_1_5_r = sum_1_5_r + 1\n",
    "sum_1_r = sum_1_r / y_test_1.shape[0]\n",
    "sum_1_5_r_ = sum_1_5_r / y_test_1.shape[0] * 100\n",
    "\n",
    "print(\"Number of unique values in y_pred_rounded : \", np.unique(y_pred_1_r).shape[0])\n",
    "print(\"Min of y_pred_rounded : \", np.min(y_pred_1_r))\n",
    "print(\"Max of y_pred_rounded : \", np.max(y_pred_1_r))\n",
    "print()\n",
    "print(\"Error is on avearage : \", sum_1_r)\n",
    "print(\"There were \", sum_1_5_r, \" correct predictions, out of \", y_test_1.shape[0], \", which is \", 100 - sum_1_5_r_,\"% error rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a63e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in y_test[:,2] :  222\n",
      "Min of y_test[:,2] :  104.152\n",
      "Max of y_test[:,2] :  152.037\n",
      "\n",
      "Number of unique values in y_pred :  1337\n",
      "Min of y_pred :  109.11509900242532\n",
      "Max of y_pred :  133.07554930692822\n",
      "\n",
      "Error is on avearage :  0.8983270988918186\n",
      "Error rate is on avearage :  0.6926994034784504 % -> for each guess, the model is of by  0.6926994034784504 %\n",
      "Let's say the target value is : 150, then the model would guess a value in the following interval :\n",
      " -> [ 149.10167290110817 , 150.89832709889183 ]\n",
      "Number of unique values in y_pred_rounded :  24\n",
      "Min of y_pred_rounded :  109.0\n",
      "Max of y_pred_rounded :  133.0\n",
      "\n",
      "Error is on avearage :  0.9108873691075404\n",
      "There were  0  correct predictions, out of  39612 , which is  100.0 % error rate\n"
     ]
    }
   ],
   "source": [
    "sum_2 = 0\n",
    "sum_2_r = 0\n",
    "for i in range(y_test_2.shape[0]):\n",
    "    sum_2 = sum_2 + np.abs(np.abs(y_pred_2[i]) - np.abs(y_test_2[i]))\n",
    "    sum_2_r = sum_2_r + np.abs(100 - (np.abs(y_pred_2[i]) * 100 / np.abs(y_test_2[i])))\n",
    "sum_2 = sum_2 / y_test_2.shape[0]\n",
    "sum_2_r = sum_2_r / y_test_2.shape[0]\n",
    "\n",
    "\n",
    "print(\"Number of unique values in y_test[:,2] : \", np.unique(y_test_2).shape[0])\n",
    "print(\"Min of y_test[:,2] : \", np.min(y_test_2))\n",
    "print(\"Max of y_test[:,2] : \", np.max(y_test_2))\n",
    "print()\n",
    "print(\"Number of unique values in y_pred : \", np.unique(y_pred_2).shape[0])\n",
    "print(\"Min of y_pred : \", np.min(y_pred_2))\n",
    "print(\"Max of y_pred : \", np.max(y_pred_2))\n",
    "print()\n",
    "print(\"Error is on avearage : \", sum_2)\n",
    "print(\"Error rate is on avearage : \", sum_2_r, \"% -> for each guess, the model is of by \", sum_2_r, \"%\")\n",
    "print(\"Let's say the target value is : 150, then the model would guess a value in the following interval :\")\n",
    "print(\" -> [\", 150 - sum_2,\",\",150 + sum_2,\"]\")\n",
    "\n",
    "\n",
    "y_pred_2_r = np.around(y_pred_2)\n",
    "\n",
    "sum_2_r = 0\n",
    "sum_2_5_r = 0\n",
    "for i in range(y_pred_2_r.shape[0]):\n",
    "    sum_2_r = sum_2_r + np.abs(np.abs(y_pred_2_r[i]) - np.abs(y_test_2[i]))\n",
    "    if(y_pred_2_r[i] == y_test_2[i]):\n",
    "        sum_2_5_r = sum_2_5_r + 1\n",
    "sum_2_r = sum_2_r / y_test_2.shape[0]\n",
    "sum_2_5_r_ = sum_2_5_r / y_test_2.shape[0] * 100\n",
    "\n",
    "print(\"Number of unique values in y_pred_rounded : \", np.unique(y_pred_2_r).shape[0])\n",
    "print(\"Min of y_pred_rounded : \", np.min(y_pred_2_r))\n",
    "print(\"Max of y_pred_rounded : \", np.max(y_pred_2_r))\n",
    "print()\n",
    "print(\"Error is on avearage : \", sum_2_r)\n",
    "print(\"There were \", sum_2_5_r, \" correct predictions, out of \", y_test_2.shape[0], \", which is \", 100 - sum_2_5_r_,\"% error rate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7176631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in y_test[:,3] :  9\n",
      "Min of y_test[:,3] :  0.0\n",
      "Max of y_test[:,3] :  8.0\n",
      "\n",
      "Number of unique values in y_pred :  1337\n",
      "Min of y_pred :  -0.20036918729748265\n",
      "Max of y_pred :  5.800333160580948\n",
      "\n",
      "Error is on avearage :  0.17144155932471927\n",
      "There were  0  correct predictions, out of  39612 , which is  100.0 % error rate\n",
      "\n",
      "Since the number of unique values is small, let's round the y_pred, to see if we get a better approximation : \n",
      "\n",
      "Number of unique values in y_pred_rounded :  7\n",
      "Min of y_pred_rounded :  -0.0\n",
      "Max of y_pred_rounded :  6.0\n",
      "\n",
      "Error is on avearage :  0.08467131172372008\n",
      "There were  36724  correct predictions, out of  39612 , which is  7.290719983843275 % error rate\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sum_3 = 0\n",
    "sum_3_5 = 0\n",
    "for i in range(y_test_3.shape[0]):\n",
    "    sum_3 = sum_3 + np.abs(np.abs(y_pred_3[i]) - np.abs(y_test_3[i]))\n",
    "    if(y_pred_3[i] == y_test_3[i]):\n",
    "        sum_3_5 = sum_3_5 + 1\n",
    "sum_3 = sum_3 / y_test_1.shape[0]\n",
    "sum_3_5_r = sum_3_5 / y_test_1.shape[0] * 100\n",
    "\n",
    "print(\"Number of unique values in y_test[:,3] : \", np.unique(y_test_3).shape[0])\n",
    "print(\"Min of y_test[:,3] : \", np.min(y_test_3))\n",
    "print(\"Max of y_test[:,3] : \", np.max(y_test_3))\n",
    "print()\n",
    "print(\"Number of unique values in y_pred : \", np.unique(y_pred_3).shape[0])\n",
    "print(\"Min of y_pred : \", np.min(y_pred_3))\n",
    "print(\"Max of y_pred : \", np.max(y_pred_3))\n",
    "print()\n",
    "print(\"Error is on avearage : \", sum_3)\n",
    "print(\"There were \", sum_3_5, \" correct predictions, out of \", y_test_3.shape[0], \", which is \", 100 - sum_3_5_r,\"% error rate\")\n",
    "print()\n",
    "print(\"Since the number of unique values is small, let's round the y_pred, to see if we get a better approximation : \")\n",
    "print()\n",
    "\n",
    "y_pred_3_r = np.around(y_pred_3)\n",
    "\n",
    "sum_3_r = 0\n",
    "sum_3_5_r = 0\n",
    "for i in range(y_test_3.shape[0]):\n",
    "    sum_3_r = sum_3_r + np.abs(np.abs(y_pred_3_r[i]) - np.abs(y_test_3[i]))\n",
    "    if(y_pred_3_r[i] == y_test_3[i]):\n",
    "        sum_3_5_r = sum_3_5_r + 1\n",
    "sum_3_r = sum_3_r / y_test_3.shape[0]\n",
    "sum_3_5_r_ = sum_3_5_r / y_test_3.shape[0] * 100\n",
    "\n",
    "print(\"Number of unique values in y_pred_rounded : \", np.unique(y_pred_3_r).shape[0])\n",
    "print(\"Min of y_pred_rounded : \", np.min(y_pred_3_r))\n",
    "print(\"Max of y_pred_rounded : \", np.max(y_pred_3_r))\n",
    "print()\n",
    "print(\"Error is on avearage : \", sum_3_r)\n",
    "print(\"There were \", sum_3_5_r, \" correct predictions, out of \", y_test_3.shape[0], \", which is \", 100 - sum_3_5_r_,\"% error rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81befbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_errors, after loading :  {'GradBoostRegressor': [0, 64.05887104917701, 0, 6.879228516611121], 'LinearRegression': [100.0, 57.472483085933554, 100.0, 7.290719983843275]}\n",
      "dict_errors, after changes :  {'GradBoostRegressor': [0, 64.05887104917701, 0, 6.879228516611121], 'LinearRegression': [100.0, 57.472483085933554, 100.0, 7.290719983843275], 'SVR': [0, 57.472483085933554, 0, 7.290719983843275]}\n"
     ]
    }
   ],
   "source": [
    "import json #ne jamais faire ça avec les import \n",
    "\n",
    "def load_dict_errors(path=\"all_errors.json\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        dict_errors = json.load(f)\n",
    "        \n",
    "    return dict_errors\n",
    "\n",
    "dict_errors = load_dict_errors()\n",
    "print(\"dict_errors, after loading : \",dict_errors)\n",
    "\n",
    "\n",
    "\n",
    "def save_dict_errors(dict_errors, path=\"all_errors.json\"):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(dict_errors, f)\n",
    "\n",
    "dict_errors['SVR'] = [0, 100 - sum_1_5_r_, 0, 100 - sum_3_5_r_]\n",
    "\n",
    "#dict_errors = { \"GradBoostRegressor\" : [100 - sum_0_5_r_, 100 - sum_1_5_r_, 100 - sum_2_5_r_, 100 - sum_3_5_r_]}\n",
    "\n",
    "print(\"dict_errors, after changes : \",dict_errors)\n",
    "save_dict_errors(dict_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4ea2d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_errors_0_2 {'lienar_regression': [0.34321702049967723, 0.017421293770233204], 'neural_network': [0.26404827656252755, 2.9858224688390417e-06], 'SGDRegressor': [0.35036686833289443, 0.010050606676439778], 'GradBoostRegressor': [0.3059346708449163, 3.882566534691418]}\n",
      "dict_errors_1_3 {'GradBoostRegressor': [64.05887104917701, 6.879228516611121], 'SVR': [57.472483085933554, 7.290719983843275], 'lienar_regression': [56.280924972230636, 5.710390790669493], 'neural_network': [45.78915480157528, 35.03483792790064], 'neer_neighboor': [54.907603756437446, 7.081187518933646], 'SGDRegressor': [56.52327577501767, 7.01050186812077]}\n",
      "dict_errors, after changes :  {'lienar_regression': [0.34321702049967723, 0.017421293770233204], 'neural_network': [0.26404827656252755, 2.9858224688390417e-06], 'SGDRegressor': [0.35036686833289443, 0.010050606676439778], 'GradBoostRegressor': [0.3059346708449163, 3.882566534691418], 'SVR': [0.26732008420568637, 0.8983270988918186]}\n",
      "dict_errors, after changes :  {'GradBoostRegressor': [64.05887104917701, 6.879228516611121], 'SVR': [57.472483085933554, 7.290719983843275], 'lienar_regression': [56.280924972230636, 5.710390790669493], 'neural_network': [45.78915480157528, 35.03483792790064], 'neer_neighboor': [54.907603756437446, 7.081187518933646], 'SGDRegressor': [56.52327577501767, 7.01050186812077]}\n"
     ]
    }
   ],
   "source": [
    "import json #ne jamais faire ça avec les import \n",
    "\n",
    "def load_dict_errors(path=\"all_errors.json\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        dict_errors = json.load(f)\n",
    "        \n",
    "    return dict_errors\n",
    "\n",
    "dict_errors_0_2 = load_dict_errors(path=\"all_errors_0_2.json\")\n",
    "dict_errors_1_3 = load_dict_errors(path=\"all_errors_1_3.json\")\n",
    "print(\"dict_errors_0_2\", dict_errors_0_2)\n",
    "print(\"dict_errors_1_3\", dict_errors_1_3)\n",
    "\n",
    "\n",
    "def save_dict_errors(dict_errors, path=\"all_errors.json\"):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(dict_errors, f)\n",
    "\n",
    "# kernel restarted, too long to retrain all the data for a model we won't use, copy pasted the above results.\n",
    "dict_errors_0_2['SVR'] = [0.26732008420568637, 0.8983270988918186]\n",
    "dict_errors_1_3['SVR'] = [57.472483085933554, 7.290719983843275]\n",
    "\n",
    "print(\"dict_errors, after changes : \",dict_errors_0_2)\n",
    "print(\"dict_errors, after changes : \",dict_errors_1_3)\n",
    "\n",
    "save_dict_errors(dict_errors_0_2, path=\"all_errors_0_2.json\")\n",
    "save_dict_errors(dict_errors_1_3, path=\"all_errors_1_3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69affb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
